% Github: https://github.com/thanhhungqb/latex-beamer-theme-cnu
% Author: thanhhungqb
% credit: https://github.com/makokal/beamer-themes

\documentclass{beamer}
% \documentclass[notes=only]{beamer}
\usetheme{CNU}

\usepackage[utf8]{inputenc}
% \usepackage{palatino}
% \usepackage[T1]{fontenc}
\usepackage{lmodern}
% \usepackage[expert]{mathdesign}
\usepackage[protrusion=true,expansion=true,tracking=true,kerning=true]{microtype}
\usepackage{diagbox}
\usepackage{algorithm2e}
\usepackage{outlines}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{listings}

\newcommand{\todo}[1]{\textcolor{red}{#1}}

\title{CNU Beamer Theme}

\author{Author}

\institute{University of Science and Technology of China}
\date {2020.08}

% \graphicspath{{imgs/}}


\setbeamercolor{note page}{bg=white}
\setbeamercolor{note title}{bg=white}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
% ===============================================================
\begin{document}


\begin{frame}[plain,t,noframenumbering]
\titlepage
\end{frame}



\begin{frame}[plain,t,noframenumbering]
	\frametitle{Outline}
  \renewcommand{\contentsname}{目录}
\tableofcontents
% \begin{itemize}
%     \item Model which reveals privacy
%     \item Intro
% \end{itemize}
% \addtocounter{framenumber}{-1}
\end{frame}
\section{problem background}
\subsection{Data for machine learning}
\begin{frame}
    \frametitle{Data for machine learning}
    \begin{itemize}
        \item \textbf{Age of big data}\\[5pt]
        machine learning becoming a hit\\
        require a large amount of data from real world\\[20pt]
        \item \textbf{Privacy data}\\[5pt]
        like human face and fingerprint...\\
        sensitive and individual but of high practical value\\
        \textbf{a tradeoff between data diversity and data utilization}
    \end{itemize}
\end{frame}

\subsection{Generative model for privacy protection}
\begin{frame}
    \frametitle{Generative model for privacy protection}
    \begin{itemize}
        \item \textbf{Generative model}\\[5pt]
        adding noise to real data without exposing the original figure\\
        little significance if only copy input to output\\[10pt]
        \item \textbf{Related work}\\[5pt]
        \textbf{DP-SGD}\cite{ref2}\\
        effective in generating high-dimensional sanitized data\\
        difficult implement\\
        \textbf{PATE}\\
        only train generators with DP guarantees\\
        high privacy costs\\
        \textbf{Fed-Avg GAN}\\
        provide user-level DP guarantees
        merely works on decentralized data
    \end{itemize}
\end{frame}

\section{Solution:generate fake data}
\subsection{Introduction of GAN}
\begin{frame}
    \frametitle{Introduction of GAN}
    \begin{itemize}
        \item \textbf{Generator}\\[5pt]
        create fake data from random sample\\
        sample $Z = (z_1,z_2,...z_n)$\\
        $\tilde{Z} = G(Z)$\\
        \item \textbf{Discriminator}\\[5pt]
        discriminate between fake and real data\\
        $D(X, G(Z)) = \begin{cases}
                      0, & \mbox{if input} \in G(Z)\\
                      1, & \mbox{if input} \in X
                      \end{cases}$
        \item \textbf{Task of two part}\\[5pt]
        \textbf{Generator}
        G(Z) closer to X, the better\\
        \textbf{Discriminator}
        distinguish G(Z) and X more, the better\\
        {$$\mathop{\min}\limits_{G}\mathop{\max}\limits_{D} V(G,D)$$}
    \end{itemize}
\end{frame}

\subsection{problem of generative model}
\begin{frame}
    \begin{itemize}
    \item Most privacy-preserving training algorithms for neural network models is \textbf{manipulating}
  the gradient information generated during backpropagation.
    \item \textbf{Methods}\\
      \textbf{Clipping the gradients} (to bound sensitivity)\\
      \textbf{Adding calibrated random noise} (to introduce stochasticity)
    \item \textbf{Problem}:limited in shallow networks and fail to sufficiently capture the sample quality of the
  original data.

  \end{itemize} 
\end{frame}

% \begin{frame}{CNU beamer theme}
% \begin{itemize}
%     \item The beamer theme with CNU style
%     \item Modified from: https://github.com/liantze/beamer-gelugor 
% \end{itemize}
% \end{frame}

\section{How to Solve privacy leakage in Generative Model}
\subsection{Review DP}
\begin{frame}
\frametitle{Review DP}
    \begin{itemize}
        \item \textbf{Neighboring dataset}\\[5pt]
        $D, D'$:differed with only a piece of data\\[20pt]
        \item \textbf{(Differential Privacy}\\[5pt]
        $Pr[M(D) \in O] \leq e^{\epsilon}Pr[M(D') \in O] + \delta$\\[5pt]
        $M$:a random algorithm\\
        $O$: output set\\
        $\epsilon$: privacy budget\\
        \quad smaller$\epsilon$, $M(D)$ and $M(D')$ closer\\
        $\delta$:disturbance\\
    \end{itemize}
\end{frame}
% \section{problem background}
% \begin{frame}
%     This is background
% \end{frame}
% \begin{frame}
    
% \end{frame}
% \section{Solution:generative fake data}
% \begin{frame}
    
% \end{frame}
% \subsection{Intro of generative model}
% \begin{frame}
    
% \end{frame}
% \section{problem of generative model}
% \begin{frame}
    
% \end{frame}
% \begin{frame}{CNU beamer theme}
% \begin{itemize}
%     \item The beamer theme with CNU style
%     \item Modified from: https://github.com/liantze/beamer-gelugor 
% \end{itemize}
% \end{frame}
\section{How to Solve privacy leakage in Generative Model}
\subsection{Review the concept DP}
\begin{frame}
    Suppose $\mathcal{M}:\R^n\to X$,
    X is called mapping Space and $\mathcal M$
     is called map from origin space into mapping space.
     For two dataset $x$ and $x^\prime$, they only has one-item difference.We call $\mathcal M$ satisfies $(\epsilon,\delta)$-privacy if following statement is true
     \begin{equation}
      Pr[\mathcal{M}(x)\in S] \leq e^{\epsilon}  Pr(\mathcal M(x^\prime )\in  S) +\delta
     \end{equation}
     What is $\mathcal M$,input space and mapping space in this scenario?
\end{frame}
\begin{frame}
  Acccording the define of \cite{ref1},$\mathcal{M}$ is the generative model.Its input space is consisted with training data and its mapping space is consisted with its output.
  Take Conditional-VAE for an example.Suppose training data takes with following formular
  \begin{equation}
    (X,y) = {(x_i,y_i)}_{i=1}^n
  \end{equation}
  it is consisted with n data samples and $x_i\in \R^n,y_i\in \R$,$x_i$ is the data(such as an image) and $y_i$ is the label of the image.$\mathcal M$ is a model which generate new data from existing data and label.

\end{frame}
\subsection{How to define privacy and utility in Generative Model}
\begin{frame}
    \frametitle{privacy define}
    Possibility is hard to quantify for NN model.So we take several ways to varify our model satisify $(\epsilon,\delta)$ privacy
\end{frame}
\subsubsection{Whether an item is sampled from the dataset}
\begin{frame}
  \frametitle{From Attackers}
  One of the goal of the attacker is to varify whether a data is from or not from the dataset.If the privacy dataset $\mathcal D$ is revealed.We can build the attacker from $\mathcal D$
  \begin{itemize}
    \item sample k data $x\in \mathcal D$ and sample k noise from $\R^n$ but $\notin \mathcal D$.Denoted as $X = x_1,x_2,\cdots,x_k$ and $Y = y_1,y_2,\cdots,y_k$
    \item $X$ is true data,we attack label $True$ to all its data and $Y$ is fake data which randomly sample from $\R^n$,so we attach $False$ label into Y,mixture $X,Y$ and its labels $T$ together
    \item build a classifier $\mathcal{C}$, which takes true/fake image as input and output the Possibility of whether the input pattern is belonged to True/Generated Data.Train the model with supervised learning method
  \end{itemize}
  In this term,privacy true image $\mathcal{X}$ is not provided for training of $\mathcal{C}$.We provided generative training data $\hat {mathcal{X}}$ which is generated from privacy dataset $\mathcal{D}$.
\end{frame}
\begin{frame}
  \frametitle{For Attackers}
  suppose P is the Possibility attacker could correctly varify the real data through generative data.We define privacy loss
  \begin{equation}
    privacy\ loss = \frac{P-0.5}{0.5}
  \end{equation}
\end{frame}
\subsubsection{utility}
\begin{frame}
  use generative data for image classifier task.We train the downstream image classifier model with Training data $T_{train}$ and validate the training accuracy with testing data $T_{test}$.There are four condition for utility measurement.
  % \begin{tabular}{|l|c|c|c|}
  % \hline
  % \diagbox{学科}{成绩}{姓名} & ABC & BBC & CED \\
  % \hline
  % 数学 & 99 & 89 & \diagbox{ce1}{ce2} \\
  % \hline
  % 化学 & \diagbox[dir=SW]{ce3}{ce4} & 67 & 82 \\   % 注意方向参数是[]
  % \hline
  % \end{tabular}
  \begin{tabular}{|l|c|c|}
  \hline
  % \diagbox{}{}{}
  \diagbox{train data}{accuracy}{test data} & privacy data & generative data  \\
  \hline
  privacy data & $p_1$ & $p_2$ \\
  \hline
  generative data & $p_3$ & $p_4$ \\   % 注意方向参数是[]
  \hline
  \end{tabular}
  We call $p_1 - p_2$ accuracy loss from the generative process
\end{frame}
% \subsection{Brief Introduction of Condition Variation Encoder(CVAE)}
% \begin{frame}
%     CVAE use label and data to 
% \end{frame}
% \section{Usage}
% \begin{frame}[fragile]{Usage}
% \begin{lstlisting}
%     \documentclass{beamer}
%     \usetheme{CNU}
%     \usepackage[utf8]{inputenc}
%     \begin{document}
%     ...
%     \end{document}

% \end{lstlisting}
% \end{frame}

% \section{Links}
% \begin{frame}{Links}
%     \begin{itemize}
%         \item Github: https://github.com/thanhhungqb/latex-beamer-theme-cnu
%         \item Overleaf: TBA
%     \end{itemize}
% \end{frame}


\begin{frame}[plain,noframenumbering]{}
  \centering \Large
  \emph{Thank you!}
\end{frame}
\begin{frame}
\bibliographystyle{plain}
\bibliography{bibfile}
  
\end{frame}
\end{document}
